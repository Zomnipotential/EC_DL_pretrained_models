{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b4f99e1",
   "metadata": {},
   "source": [
    "# Pretrained Models - Kunskapskontroll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5309418-5de6-4343-a72d-43d145c0f163",
   "metadata": {},
   "source": [
    "**Obligatoriskt att fylla i uppgifterna nedan.**\n",
    "\n",
    "Namn: \n",
    "\n",
    "Vem du har presenterat för: \n",
    "\n",
    "Datum då du presenterade: \n",
    "\n",
    "**Kunskapskontrollen lämnas in på Omniway.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44866b68-a527-4ff6-a936-8ab6c01a2623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a48e6fe0-efb0-4aa1-bf5d-21201a0f46af",
   "metadata": {},
   "source": [
    "**It is possible to load pretrained models which is a powerful concept.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b90574",
   "metadata": {},
   "source": [
    "Model implementation: \n",
    "https://keras.io/api/applications/#usage-examples-for-image-classification-models\n",
    "\n",
    "Class list for ResNet50, for example tennis ball is 852:\n",
    "https://deeplearning.cms.waikato.ac.nz/user-guide/class-maps/IMAGENET/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc038c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-17 16:21:50.980736: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f3c1e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "620f8050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "#import io\n",
    "#from io import BytesIO\n",
    "\n",
    "# Define the URL of the example image\n",
    "img_url = 'https://storage.googleapis.com/download.tensorflow.org/example_images/592px-Red_sunflower.jpg'\n",
    "with urllib.request.urlopen(img_url) as url:\n",
    "    img = image.load_img(BytesIO(url.read()), target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d699b0c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = image.img_to_array(img)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "623238c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.expand_dims(x, axis=0)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4bf38543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet50/preprocess_input\n",
    "x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d89f33d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 467ms/step\n",
      "Predicted: [('n11939491', 'daisy', 0.5811759), ('n02206856', 'bee', 0.24989869), ('n03991062', 'pot', 0.011351688)]\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(x)\n",
    "# decode the results into a list of tuples (class, description, probability)\n",
    "# (one such list for each sample in the batch)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])\n",
    "# Predicted: [(u'n02504013', u'Indian_elephant', 0.82658225), (u'n01871265', u'tusker', 0.1122357), (u'n02504458', u'African_elephant', 0.061040461)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc00d598",
   "metadata": {},
   "source": [
    "# 1. Take some pictures yourself and predict their class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d7d93ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Users/matt/Documents/Documents_Afsaneh/Courses/IT_Hogskolan/Projects/final_project/venv/lib/python3.9/site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/matt/Documents/Documents_Afsaneh/Courses/IT_Hogskolan/Projects/final_project/venv/lib/python3.9/site-packages (from requests) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/matt/Documents/Documents_Afsaneh/Courses/IT_Hogskolan/Projects/final_project/venv/lib/python3.9/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/matt/Documents/Documents_Afsaneh/Courses/IT_Hogskolan/Projects/final_project/venv/lib/python3.9/site-packages (from requests) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/matt/Documents/Documents_Afsaneh/Courses/IT_Hogskolan/Projects/final_project/venv/lib/python3.9/site-packages (from requests) (2023.5.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7a2c10-2229-452e-94d6-64e5c36684bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 151ms/step\n",
      "Predicted: [('n04548362', 'wallet', 0.89398956), ('n04026417', 'purse', 0.08407851), ('n03223299', 'doormat', 0.012034052)]\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Predicted: [('n04557648', 'water_bottle', 0.37683392), ('n02823428', 'beer_bottle', 0.3497757), ('n04591713', 'wine_bottle', 0.111103)]\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "Predicted: [('n04120489', 'running_shoe', 0.62979954), ('n01985128', 'crayfish', 0.18412602), ('n01983481', 'American_lobster', 0.08015384)]\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "from io import BytesIO\n",
    "import re\n",
    "import glob\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "il_1 = 'IMG_3995.png'\n",
    "il_2 = 'IMG_3996.png'\n",
    "il_3 = 'IMG_3997.png'\n",
    "il_4 = 'IMG_3998.png'\n",
    "il_5 = '592px_Red_sunflower.jpg'\n",
    "il_6 = 'https://storage.googleapis.com/download.tensorflow.org/example_images/592px-Red_sunflower.jpg'\n",
    "\n",
    "# Run the test with the above images\n",
    "#image_files = [il_1, il_2, il_3, il_4, il_5, il_6]\n",
    "\n",
    "# Or choose a folder to load images from\n",
    "image_files = load_images_from_folder('./')\n",
    "\n",
    "# Check if the file is an image of any format\n",
    "def is_image(filename):\n",
    "    try:\n",
    "        i = Image.open(filename)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# Find all images from the 'folder' and return them in a list\n",
    "def load_images_from_folder(folder):\n",
    "    image_files = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if is_image(filename):\n",
    "            image_files.append(filename)\n",
    "    return image_files\n",
    "\n",
    "# Choose to use images from local directories or from web\n",
    "for img_url in image_files:\n",
    "    if re.match(r'^https?://', img_url) or re.match(r'^ftp://', img_url):\n",
    "        response = requests.get(img_url)\n",
    "        response.raise_for_status()  # Ensure the request was successful\n",
    "        img_data = response.content\n",
    "        image_url = BytesIO(img_data)\n",
    "        print('Real URL:', image_url)\n",
    "    else:\n",
    "        image_url = img_url\n",
    "\n",
    "    img = image.load_img(image_url, target_size=(224, 224))\n",
    "\n",
    "    # Show the image and convert to an array\n",
    "    img.show()\n",
    "    x = image.img_to_array(img)\n",
    "\n",
    "    # Make the files ready for feeding into the network\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "\n",
    "    # Do some preprocessing on the image\n",
    "    x = preprocess_input(x)\n",
    "    preds = model.predict(x)\n",
    "\n",
    "    print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafcd7f8-406a-462c-9601-02ba78c5e29f",
   "metadata": {},
   "source": [
    "# 2. Answer the question: Why is \"Pretrained models\" a very powerful concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a82a29c",
   "metadata": {},
   "source": [
    "Pretrained models save lots of training time. Those who generate pretrained models, ususally \n",
    "have access to enough computational resources and enough many training examples to train the \n",
    "model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
